g = g + geom_vline(xintercept = xitc, size = 3)
g
}
manipulate(myplot(sigma, mua, n, alpha), sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32), n = slider(1, 50, step = 1,
initial = 16), alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
plot(c(-3, 6),c(0, dnorm(0)), type = "n", frame = FALSE, xlab = "Z value", ylab = "")
library(manipulate)
mu0 = 30
myplot <- function(sigma, mua, n, alpha) {
g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))
g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mu0,
sd = sigma/sqrt(n)), size = 2, col = "red")
g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mua,
sd = sigma/sqrt(n)), size = 2, col = "blue")
xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
g = g + geom_vline(xintercept = xitc, size = 3)
g
}
manipulate(myplot(sigma, mua, n, alpha), sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32), n = slider(1, 50, step = 1,
initial = 16), alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
library(tm)
install.packages("tm")
library(tm)
library(dplyr)
library(rvest)
library(ggmap)
library(leaflet)
library(RColorBrewer)
library(dplyr)
library(rvest)
install.packages("rvest")
library(rvest)
library(ggmap)
install.packages("ggmap")
rm(list=ls())
library(ggmap)
install.packages("leaflest")
install.packages("leaflet")
library(leaflet)
install.packages("RColorBrewer")
library(RColorBrewer)
url<-html("http://www.visitithaca.com/attractions/wineries.html")
selector_name<-".pageListingHeader"
fnames<-html_nodes(url, selector_name) %>%
html_text()
library(dplyr)
library(rvest)
library(ggmap)
library(leaflet)
library(RColorBrewer)
??selectr
?selctr
fnames<-html_nodes(url, selector_name) %>%
html_text()
package(selectr)
install.package("selectr")
install.packages("selectr")
package(selectr)
library(selectr)
fnames<-html_nodes(url, selector_name) %>%
html_text()
fnames
url<-html("http://www.visitithaca.com/attractions/waterfalls.html")
fnames<-html_nodes(url, selector_name) %>%
html_text()
fnames
head(fnames)
faddress<-html_nodes(url, selector_address) %>%
html_text()
selector_name<-"strong"
faddress<-html_nodes(url, selector_address) %>%
html_text()
fnames<-html_nodes(url, selector_name) %>%
html_text()
fnames
selector_name<-"strong td:n-th-child(2)"
fnames<-html_nodes(url, selector_name) %>%
html_text()
selector_name<-"strong td:nth-child(2)"
fnames<-html_nodes(url, selector_name) %>%
html_text()
fnames
selector_name<-"strong td:nth-child(2) strong:first-child"
fnames<-html_nodes(url, selector_name) %>%
html_text()
fnames
selector_name<-"strong"
fnames<-html_nodes(url, selector_name) %>%
html_text()
fnames
fname<-".results_summary_item_details td:nth-child(3) strong:first-child"
fnames<-html_nodes(url, selector_name) %>%
html_text()
fma,es
fnames
head fnames
head(fnames)
geocodes<-geocode(fname,output="latlona")
geocodes
geocodes<-geocode(fname,output="latlona")
fnames
geocodes<-geocode(fnames,output="latlona")
geocodes
geocodes
install.packages("caret")
fname<-"td , strong:nth-child(1)"
url<-html("http://www.visitithaca.com/attractions/waterfalls.html")
library(rvest)
library(dplyr)
library(ggmap)
library(leaflet)
html_text
url<-html("http://www.visitithaca.com/attractions/waterfalls.html")
url
fnames<-html_nodes(url, selector_name) %>% html_text()
fnames
install.packages("caret")
install.packages("kernlab")
rm(list=ls())
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
install.packages("ElemStatLearn")
library(ElemStatLearn)
install.packages("pgmm")
library(pgmm)
install.packages("rpart")
library(rpart)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain<-createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
dim(training);dim(testing)
set.seed(125)
modFit<-train(Case ~ ., method="rpart",data=segmentationOriginal)
package(e1071)
library(e1071)
install.packages("e1071")
library(e1071)
modFit<-train(Case ~ ., method="rpart",data=segmentationOriginal)
print(modfit$finalModel)
print(modFit$finalModel)
predict(modFit,newdata=testing)
modFit<-train(Case ~ ., method="rpart",data=segmentationOriginal)
testing
testing$TotalIntenCh2==23000
predict(modFit,newdata=c(TotalIntench2=23000,fiberWidthCh1=10,PerimStatusCh1=2))
predict(modFit,newdata=c(TotalIntench2=23000,fiberWidthCh1=10,PerimStatusCh1=2))
predict(modFit,newdata=c(TotalIntench2=23000,FiberWidthCh1=10,PerimStatusCh1=2))
predict(modFit,newdata=data.frame(c(TotalIntench2=23000,FiberWidthCh1=10,PerimStatusCh1=2)))
modFit<-train(Case ~ ., method="rpart",data=training)
print(modFit)
print(modFit$finalModel)
modFit<-train(Case ~ ., method="rpart",data=training)
set.seed(125)
training<-subset(AppliedPredictiveModeling, Case="Training")
training<-subset(AppliedPredictiveModeling, Case=="Training")
training<-subset(segmentationOriginal, Case=="Training")
modFit<-train(Case ~ ., method="rpart",data=training)
print(modFit$FinalModel)
rm(modFit)
modFit<-train(Case ~ ., method="rpart",data=training)
training
training<-subset(segmentationOriginal, Case=="Train")
training
modFit<-train(Case ~ ., method="rpart",data=training)
modFit<-train(Case ~ ., method="rpart",data=training)
training
rm(training)
rm(test)
rm(testing)
training<-subset(x=segmentationOriginal,Case="Train")
modFit <-train(Class ~ ., method="rpart", data=training)
print(modFit$finalModel)
library(pgmm)
data(olive)
olive=olive[,-1]
newdata<-as.data.frame(t(colMeans(olive)))
omodFit<-train(Area ~ ., method="rpart",data=olive)
olive$Area
predict(omodFit,data=newdata)
newdata
olive
newdata
colMeans(olive)
rm(omodFit)
omodFit<-train(Area ~ ., method="rpart",data=newdata)
omodFit<-train(Area ~ ., method="rpart",data=olive)
predict(omodFit,data=newdata)
rm(list=ls())
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train=sample(1:dim(SAheart)[1], size=dim(SAheart)[1]/2,replace=F)
trainSA=SAheart[train,]
testSA=SAheart[-train,]
set.seed(13234)
mylogit<-glm(formula=chd ~ age+alcohol+obesity+tobacco+typea+ldl, data=SAheart)
mylogit
misClass=function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predict(logit,newdata=testSA)
predict(mylogit,newdata=testSA)
logitTest<-predict(mylogit,newdata=testSA)
logitTrain<-predict(mylogit,newdata=trainSA)
misClass=function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
misClass()
SAmodFit<-train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, data=SAtrain, method="glm",family="binomial")
SAmodFit<-train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm",family="binomial")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test
str(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
set.seed(33833)
vmodFit<-train(y ~ ., model="rf",data=vowel.train)
vmodFit$FinalModel
vmodFit
? varImp
predict(vmodFit,newdata=vowel.test)
varIMp
varImp
varImp(vmodFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
seed(33833)
set.seed(33833)
vowel
vowel.train
head vowel.train
head(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
head(vowel.test)
str(vowel.train)
rfModel<-train(vowel.train$y ~ ., method="rf")
library(caret)
rfModel<-train(vowel.train$y ~ ., method="rf")
rfModel<-train(vowel.train$y ~ ., method="rf", data=vowel.train)
gbmModel<-train(vowel.train$y ~ ., method="gbm",data=vowel.train)
pred1<-predict(rfModel,vowel.test)
pred2<-predict(gbmModel,vowel.test)
qplot(pred1,pred2,data=vowel.test)
rfModel
gbmModel
pred1
pred2
vowel.test$y
accuracy(postResample(vowel.test$y,rfModel))
??accuracy
library(AppliedPredictiveModeling)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
install.packages("forecast")
library(e1071)
accuracy
postResample(vowel.train$y, rfModel)
postResample(vowel.train$y, pred1)
postResample(vowel.train$y, pred2)
combFit<-train(vowel$y ~ ., method="gam",data=predDF)
predDF<-data.frame(pred1,pred2,y=vowel.test$y)
combFit<-train(vowel$y ~ ., method="gam",data=predDF)
combFit<-train(vowel.test$y ~ ., method="gam",data=predDF)
combPred<predict(combFit,predDF)
combPred<-predict(combFit,predDF)
postResample(vowel.train$y,combPred)
postResample(vowel.test$y,combPred)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData=data.frame(daignosis,predictors)
adData=data.frame(diagnosis,predictors)
inTrain<-createDataPartition(adData$diagnosis,p=3/4)[[1]]
training=adData[inTrain]
training=adData[inTrain,]
testing=adData[-inTrain,]
set.seed(62433)
str(adData)
rfModel<-train(adData$diagnosis ~ ., model="rf",data=adData)
rfModel<-train(training$diagnosis ~ ., model="rf",data=training)
gbmModel<-train(training$diagnosis ~ ., model="gbm",data=training)
rfAcc<-postResample(test$diagnosis,rfModel)
rfAcc<-postResample(testing$diagnosis,rfModel)
rfTest<-predict(rfModel,testing)
rfAcc<-postResample(testing$diagnosis,rfTest)
rfAcc
gbmTest<-predict(gbmModel,testing)
gbmAcc<-postResample(testing$diagnosis,gbmTest)
gbmAcc
ldaModel<-train(training$diagnosis ~ ., model="lda",data=training)
ldaTest<-predict(ldaModel,testing)
ldaAcc<-postResample(testing$diagnosis,ldaTest)
ldaAcc
predDF<-data.frame(rfModel,ldaModel,ldaModel,diagnosis=test$diagnosis)
predDF<-data.frame(rfModel,ldaModel,ldaModel,diagnosis=testing$diagnosis)
predDF<-data.frame(rfModel,ldaModel,ldaModel)
predDF<-data.frame(rfModel,gbmModel,ldaModel)
predDF<-data.frame(rfModel,gbmModel)
predDF<-data.frame(rfModel)
rm(predDF)
predDF<-data.frame(rfModel)
predDF<-data.frame(gbmModel)
predDF<-data.frame(rfTest,gbmTest,ldaTest,diagnosis=testing.diagnosis)
predDF<-data.frame(rfTest,gbmTest,ldaTest,diagnosis=testing$diagnosis)
combFIt<-train(diagnosis ~ ., method="gam",data=predDF)
combPred<-predict(combFit, predDF)
postResample(combPred,testing$diagnosis)
str(predDF)
rm(combFit)
rm(combFIt)
combFit<-train(diagnosis ~ ., method="gam",data=predDF)
combPred<-predict(combFit, predDF)
postResample(CombPred, testing$diagnosis)
postResample(combPred, testing$diagnosis)
gbmAcc-ldaAcc
set.seed(3523)
library(AppliedPredictiveMOdeling)
library(AppliedPredictiveMoeling)
library(AppliedPredictiveModeling)
data(concrete)
rm(inTrain)
rm(com*)
rom(combFit)
rm(combFit)
rm(comPr)
rm(combPred)
rm(inTrain)
rm(training)
rm(testing)
inTrain=createDataPartition(concrete$CompressiveStrength, p=3/4)[[1]]
training<-concrete[inTrain,]
testing<-concrete[-inTrain,]
set.seed(233)
??lasso
rm(pred1,pred2)
rm(predDF)
rm(vowel.test,vowel.train)
rm(diagnosis)
rm(fname,fnames,gbmAcc,gbmModel,gbmTest,ldaAc,ldaModel,ldaTest)
rm(url)
rm(selector_name)
rm(rfTestrfM,rfAcc)
rm(ldaAcc)
rm(rfModel)
rm(rfTe)
rm(rfTest)
mod<-train(concrete$CompressiveStrength ~ ., data=concrete,model="lasso")
set.seed(233)
mod<-train(concrete$CompressiveStrength ~ ., data=concrete,model="lasso")
?plot.ene
?plot.enet
?plot.enet
library(elasticnet)
mod
modtest<-predict(mod,testing$CompressiveStrength)
mod$finalModel
plot(mod$finalMOdel)
install.packages("elasticnet")
library(elasticnet)
?plot.enet
plot(mod)
str(testing)
plot(mod,Age)
plot(mod,testing$Age)
testing$Age
testing$Concrete
testing$Cement
modtest<-predict(mod,train$CompressiveStrength)
rm(list=ls())
library(rCharts)
?dTable
??dTable
airquality
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
fit<-lm(mpg ~ hp,data=mtcars)
plot(mpg ~ hp, data=mtcars)
abline(fit)
fit <-lm(mpg ~ hp + am,data=mtcars)
plot(mpg ~ hp+am,data=mtcars)
plot(mpg ~ hp, data=mtcars)
plot(mpg ~ hp+am,data=mtcars)
plot(mpg ~ hp+am,data=mtcars)
mtcars
str(mtcars)
levels(mtcars$am)<-c("auto","manual")
plot(mpg ~ hp+am,data=mtcars,which=1)
abline(fit)
plot(mpg ~ hp, data=mtcars,which=1)
plot(mpg ~ hp+am, data=mtcars,which=1)
plot(mpg ~ hp+cyl, data=mtcars,which=1)
plot(mpg ~ hp+disp, data=mtcars,which=1)
warmomgs)_
warning()
fit<-lm(mpg ~ hp + cyl,data=mtcars)
plot(fit, which=1:2)
plot(fit, which=1)
plot(fit, which=2)
plot(fit, which=3)
plot(fit, which=4)
plot(fit, which=5)
plot(fit, which=6)
fit<-lm(mpg, hp + cyl,data=mtcars)
plot(mpg ~ hp, data=mtcars)
plot(mpg ~ hp + cyl, data=mtcars)
data=mtcars)
?lm
?dgamma
?predict
?colSums
load("D:/Craig/Academic/Hopkins/Data Science/0. Capstone/Yelp Dataset/yelp_dataset_challenge_academic_dataset/.RData")
rm(iris)
rm(mtcars)
rm(fit)
biz_dat<-dat
biz_dat_flat<-flatdat
save.image("D:/Craig/Academic/Hopkins/Data Science/0. Capstone/Yelp Dataset/yelp_dataset_challenge_academic_dataset/.RData")
json_file<-
rm(list=ls())
setwd("D:/Craig/Academic/Hopkins/Data Science/0. Capstone/Yelp Dataset/yelp_dataset_challenge_academic_dataset/Capstone-Yelp")
library(jsonlite)
library(UsingR)
library(leaflet)
library(maps)
json_file<-"yelp_academic_dataset_business.json"
biz_dat <- fromJSON(sprintf("[%s]", paste(readLines(json_file), collapse=",")))
cats<-biz_dat$categories
listcats<-unlist(cats)
allcat<-table(listcats)
category_table<-as.data.frame(allcat)
restaurants<-grep(pattern="Restaurants",biz_dat$categories)
bars<-biz_rest<-biz_dat[restaurants,]
bizrates<-data.frame(biz_rest$business_id,biz_rest$stars,biz_rest$longitude,biz_rest$latitude, biz_rest$state,
biz_rest$attributes$`Take-out`,biz_rest$attributes$`Takes Reservations`,biz_rest$attributes$`Wi-Fi`,
biz_rest$attributes$Caters)
#
cc<-complete.cases(bizrates)
bizrates<-bizrates[cc,]
write.table(bizrates,"bizrates.dat")
mymap<-leaflet() %>%
addTiles() %>%
addTiles(urlTemplate = "http://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}.png")  %>%
mapOptions(zoomToLimits="always") %>%
addMarkers(lat=bizrates$biz_rest.latitude,lng=bizrates$biz_rest.longitude,
clusterOptions = markerClusterOptions(),popup=bizrates$biz_rest.business_id)
mymap
library(shiny)
View(bizrates)
View(bizrates)
runApp()
runApp()
num_biz<-nrow(biz_dat)
num_rest<-nrow(bars)
num_complete<-nrows(bizrates)
num_complete<-nrow(bizrates)
hist(num_biz,num_rest,num_complete)
plot(num_biz,num_rest,num_complete)
?plot
?barplot
barplot(c(num_biz,num_rest,num_complete))
barplot(c(num_biz,num_rest,num_complete), main="Number of Business",names.arg=c("Businesses","Restaurants","Full Service")
)
barplot(c(num_biz,num_rest,num_complete), main="Number of Business",names.arg=c("Businesses","Restaurants","Full Service"))
allcat
nrow(allcat)
allcat(bizrates$biz_rest.attributes..Wi.Fi.)
allcats(bizrates$biz_rest.attributes..Wi.Fi.)
unlist(bizrates$biz_rest.attributes..Wi.Fi.)
table(unlist(bizrates$biz_rest.attributes..Wi.Fi.))
numrows(cc)
cc
cc[1:5,]
cc[1:5
]
bizrates[3,]
bizrates<-data.frame(biz_rest$business_id,biz_rest$stars,biz_rest$longitude,biz_rest$latitude, biz_rest$state,
biz_rest$attributes$`Take-out`,biz_rest$attributes$`Takes Reservations`,biz_rest$attributes$`Wi-Fi`,
biz_rest$attributes$Caters)
#
#cc<-complete.cases(bizrates)
#bizrates<-bizrates[cc,]
write.table(bizrates,"bizrates.dat")
runApp()
bizrates<-data.frame(biz_rest$business_id,biz_rest$stars,biz_rest$longitude,biz_rest$latitude, biz_rest$state,
biz_rest$attributes$`Take-out`,biz_rest$attributes$`Takes Reservations`,biz_rest$attributes$`Wi-Fi`,
biz_rest$attributes$Caters)
#
cc<-complete.cases(bizrates)
bizrates<-bizrates[cc,]
write.table(bizrates,"bizrates.dat")
runApp()
source('D:/Craig/Academic/Hopkins/Data Science/0. Capstone/Yelp Dataset/yelp_dataset_challenge_academic_dataset/Capstone-Yelp/pre_process.R')
knit_with_parameters('D:/Craig/Academic/Hopkins/Data Science/0. Capstone/Yelp Dataset/yelp_dataset_challenge_academic_dataset/Capstone-Yelp/Lewis-Capstone-Final.Rmd')
runApp()
crogger
+ UI.R/Server.R and preprocessed data available at https://github.com/crogger62/Capstone-Yelp
+ UI.R/Server.R and preprocessed data available at "https://github.com/crogger62/Capstone-Yelp""
